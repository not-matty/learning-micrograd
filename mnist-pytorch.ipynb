{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "x_label shape: (60000, 1)\n",
      "x_train shape: (60000, 784)\n",
      "x_test shape: (10000, 1)\n",
      "x_test shape: (10000, 784)\n",
      "X_train_tensor shape: torch.Size([60000, 784])\n",
      "y_train_tensor shape: torch.Size([60000])\n",
      "X_test_tensor shape: torch.Size([10000, 784])\n",
      "y_test_tensor shape: torch.Size([10000])\n",
      "Number of training batches: 938\n",
      "Number of testing batches: 157\n",
      "MLP(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (dropout1): Dropout(p=0.2, inplace=False)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (dropout2): Dropout(p=0.2, inplace=False)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 938/938 [00:02<00:00, 358.12batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.2637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 938/938 [00:02<00:00, 400.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.1086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 938/938 [00:02<00:00, 392.14batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.0768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 938/938 [00:02<00:00, 397.80batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.0611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 938/938 [00:02<00:00, 411.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.0522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 938/938 [00:02<00:00, 400.15batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.0433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 938/938 [00:02<00:00, 423.36batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.0382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 938/938 [00:02<00:00, 395.77batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.0345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 938/938 [00:02<00:00, 385.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.0319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 938/938 [00:02<00:00, 417.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.0278\n",
      "Accuracy of the MLP on the 10000 test images: 98.18%\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "File mnist_mlp.pth cannot be opened.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=164'>165</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAccuracy of the MLP on the 10000 test images: \u001b[39m\u001b[39m{\u001b[39;00mtest_accuracy\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=166'>167</a>\u001b[0m \u001b[39m# --- Saving the Model (Optional) ---\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=167'>168</a>\u001b[0m \n\u001b[1;32m    <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=168'>169</a>\u001b[0m \u001b[39m# Save the trained model\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=169'>170</a>\u001b[0m torch\u001b[39m.\u001b[39;49msave(model\u001b[39m.\u001b[39;49mstate_dict(), \u001b[39m'\u001b[39;49m\u001b[39mmnist_mlp.pth\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#W0sdW50aXRsZWQ%3D?line=170'>171</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mModel saved to mnist_mlp.pth\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/serialization.py:651\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    648\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    650\u001b[0m \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 651\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    652\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    653\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/serialization.py:525\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    524\u001b[0m     container \u001b[39m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 525\u001b[0m \u001b[39mreturn\u001b[39;00m container(name_or_buffer)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/serialization.py:496\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39mPyTorchFileWriter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_stream))\n\u001b[1;32m    495\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 496\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49mPyTorchFileWriter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: File mnist_mlp.pth cannot be opened."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Optional: For progress visualization\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "# --- Data Preparation ---\n",
    "train_data = pd.read_csv('/Users/matthew/Downloads/archive/mnist_train.csv')\n",
    "test_data = pd.read_csv('/Users/matthew/Downloads/archive/mnist_test.csv')\n",
    "\n",
    "y_train = train_data.iloc[:, [0]]\n",
    "X_train = train_data.iloc[:, 1:]\n",
    "y_test = test_data.iloc[:, [0]]\n",
    "X_test = test_data.iloc[:, 1:]\n",
    "\n",
    "print(f\"x_label shape: {y_train.shape}\")\n",
    "print(f\"x_train shape: {X_train.shape}\")\n",
    "print(f\"x_test shape: {y_test.shape}\")\n",
    "print(f\"x_test shape: {X_test.shape}\")\n",
    "\n",
    "X_train_np = X_train.values.astype(np.float32)\n",
    "y_train_np = y_train.values.astype(np.int64).squeeze()  # Shape: (60000,)\n",
    "X_test_np = X_test.values.astype(np.float32)\n",
    "y_test_np = y_test.values.astype(np.int64).squeeze()    # Shape: (10000,)\n",
    "\n",
    "# Normalize the feature data (values between 0 and 1)\n",
    "X_train_np /= 255.0\n",
    "X_test_np /= 255.0\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.from_numpy(X_train_np)\n",
    "y_train_tensor = torch.from_numpy(y_train_np)\n",
    "X_test_tensor = torch.from_numpy(X_test_np)\n",
    "y_test_tensor = torch.from_numpy(y_test_np)\n",
    "\n",
    "# Verify shapes\n",
    "print(f\"X_train_tensor shape: {X_train_tensor.shape}\")\n",
    "print(f\"y_train_tensor shape: {y_train_tensor.shape}\")\n",
    "print(f\"X_test_tensor shape: {X_test_tensor.shape}\")\n",
    "print(f\"y_test_tensor shape: {y_test_tensor.shape}\")\n",
    "\n",
    "# --- Creating Datasets and DataLoaders ---\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Define hyperparameters\n",
    "batch_size = 64\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f'Number of training batches: {len(train_loader)}')\n",
    "print(f'Number of testing batches: {len(test_loader)}')\n",
    "\n",
    "# --- Defining the MLP Model ---\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size=784, hidden_sizes=[512, 256], num_classes=10, dropout=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        # Define the first hidden layer\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        \n",
    "        # Define the second hidden layer\n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        \n",
    "        # Define the output layer\n",
    "        self.fc3 = nn.Linear(hidden_sizes[1], num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.dropout1(out)\n",
    "        \n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.dropout2(out)\n",
    "        \n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "# Initialize the model\n",
    "model = MLP().to(device)\n",
    "print(model)\n",
    "\n",
    "# --- Setting Up Loss Function and Optimizer ---\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# --- Training the Model ---\n",
    "\n",
    "# Define number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Iterate over batches with progress bar\n",
    "    for batch_X, batch_y in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch'):\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Calculate average loss over the epoch\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "# --- Evaluating the Model ---\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch_X, batch_y in data_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "test_accuracy = evaluate(model, test_loader)\n",
    "print(f'Accuracy of the MLP on the 10000 test images: {test_accuracy:.2f}%')\n",
    "\n",
    "# --- Saving the Model (Optional) ---\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'mnist_mlp.pth')\n",
    "print('Model saved to mnist_mlp.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
